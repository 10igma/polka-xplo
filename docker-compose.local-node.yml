# Docker Compose override for co-located full-node / collator deployment
#
# Use this when the indexer runs on the SAME server as a Substrate node
# (validator, collator, or archive node) with a local RPC endpoint.
#
# Usage:
#   docker compose -f docker-compose.yml -f docker-compose.local-node.yml up -d
#
# Combined with a chain override (e.g. Ajuna on a local collator):
#   docker compose \
#     -f docker-compose.yml \
#     -f docker-compose.ajuna.yml \
#     -f docker-compose.local-node.yml \
#     up -d
#
# How it works:
#   LOCAL_NODE_URL is prepended to the RPC pool. The latency-weighted
#   router will naturally send most traffic to it (sub-ms latency vs
#   50-200 ms for public RPCs). Public RPCs in ARCHIVE_NODE_URL serve
#   as automatic fallback if the local node is temporarily unreachable.
#
# Prerequisites:
#   - Your Substrate node must expose its RPC on a port accessible from
#     the Docker container. The default Substrate RPC port is 9944,
#     but collators often remap it (e.g. 9733 for Ajuna).
#     Verify with: curl -s -d '{"jsonrpc":"2.0","id":1,"method":"system_health","params":[]}' \
#                       -H "Content-Type: application/json" http://127.0.0.1:<port>
#   - If the node binds to 127.0.0.1, you need either:
#       a) network_mode: host (used below), or
#       b) --rpc-external on the Substrate node, or
#       c) extra_hosts: ["host.docker.internal:host-gateway"]
#
# The default below uses host networking so the container sees
# localhost:9944 as the Substrate node. If you prefer bridge
# networking, comment out network_mode and use extra_hosts instead.
#
# Resource limits:
#   When sharing a server with a collator/validator, the node MUST have
#   priority. All explorer containers are capped in CPU, memory, and
#   given low CPU shares / OOM priority so the kernel favours the
#   collator under pressure.
#
#   Adjust the limits below to match your server spec. The defaults
#   assume a 4-8 core / 16-32 GB server where ~50% of resources are
#   reserved for the collator.

services:
  explorer-indexer:
    # Host networking — container shares the host's network stack,
    # so ws://127.0.0.1:9944 reaches the co-located Substrate node.
    network_mode: host
    # --- Resource limits (protect the collator) ---
    cpus: ${INDEXER_CPUS:-2.0}
    mem_limit: ${INDEXER_MEM_LIMIT:-4g}
    memswap_limit: ${INDEXER_MEM_LIMIT:-4g}
    cpu_shares: 256          # Lower than default (1024) — collator gets priority
    oom_score_adj: 500       # Kernel kills indexer before collator under OOM
    environment:
      # Local node endpoint (prepended to the RPC pool as primary)
      # Default is 9944; override via .env file (e.g. LOCAL_NODE_URL=ws://127.0.0.1:9733)
      LOCAL_NODE_URL: ${LOCAL_NODE_URL:-ws://127.0.0.1:9944}
      # Database and Redis also need host addresses when using host networking
      DATABASE_URL: ${DATABASE_URL:-postgresql://polkaxplo:polkaxplo@127.0.0.1:5432/polkaxplo}
      REDIS_URL: ${REDIS_URL:-redis://127.0.0.1:6379}
      # Lower concurrency to reduce CPU/IO pressure on the collator
      BACKFILL_CONCURRENCY: ${BACKFILL_CONCURRENCY:-4}

  explorer-db:
    # --- Resource limits (protect the collator) ---
    cpus: ${DB_CPUS:-1.5}
    mem_limit: ${DB_MEM_LIMIT:-3g}
    memswap_limit: ${DB_MEM_LIMIT:-3g}
    cpu_shares: 256
    oom_score_adj: 300

  explorer-redis:
    # --- Resource limits (protect the collator) ---
    cpus: ${REDIS_CPUS:-0.5}
    mem_limit: ${REDIS_MEM_LIMIT:-512m}
    memswap_limit: ${REDIS_MEM_LIMIT:-512m}
    cpu_shares: 128
    oom_score_adj: 400

  explorer-web:
    # --- Resource limits (protect the collator) ---
    cpus: ${WEB_CPUS:-1.0}
    mem_limit: ${WEB_MEM_LIMIT:-1g}
    memswap_limit: ${WEB_MEM_LIMIT:-1g}
    cpu_shares: 128
    oom_score_adj: 600       # Least critical — killed first
